# ğŸ§ª SystÃ¨me de Tests DSL Ruby/JS Hybride

Un systÃ¨me complet de tests automatiques pour votre DSL Ruby/JavaScript hybride, avec dÃ©tection d'erreurs de parsing, analyse de performance et rapports dÃ©taillÃ©s.

## ğŸš€ Vue d'ensemble

Ce systÃ¨me teste automatiquement :
- âœ… **Transpilation Ruby â†’ JavaScript** (A.new, blocs do...end, etc.)
- âœ… **APIs du Framework A** (mÃ©thodes, Ã©vÃ©nements, chaÃ®nage)
- âœ… **Syntaxe mixte Ruby/JS** (interpolation, conditionals)
- âœ… **DÃ©tection d'erreurs** avec suggestions d'amÃ©lioration
- âœ… **Tests de performance** et mÃ©triques
- âœ… **Rapports HTML/JSON** interactifs

## ğŸ“ Structure des fichiers

```
my_solution/
â”œâ”€â”€ tests/                          # SystÃ¨me de tests SQH existant
â”œâ”€â”€ dsl-tests/                      # Nouveau systÃ¨me de tests DSL
â”‚   â”œâ”€â”€ dsl-test-suite.js          # Moteur de tests principal
â”‚   â”œâ”€â”€ dsl-test-config.js         # Configuration avancÃ©e
â”‚   â”œâ”€â”€ dsl-test-runner.sh         # Script d'exÃ©cution
â”‚   â”œâ”€â”€ hyper_squirrel.js          # Votre parser principal
â”‚   â”œâ”€â”€ transpiller.js             # Parser de secours
â”‚   â”œâ”€â”€ prism-parser.js            # Parser WASM (optionnel)
â”‚   â””â”€â”€ test-reports/              # Rapports gÃ©nÃ©rÃ©s
â””â”€â”€ README.md                      # Ce fichier
```

## ğŸ› ï¸ Installation et Setup

### 1. PrÃ©requis

```bash
# Node.js 16+ requis
node --version  # v16.0.0+

# Outils optionnels pour rapports avancÃ©s
sudo apt install jq bc  # Ubuntu/Debian
brew install jq bc      # macOS
```

### 2. Setup initial

```bash
# CrÃ©er le rÃ©pertoire de tests DSL
mkdir -p my_solution/dsl-tests
cd my_solution/dsl-tests

# Copier vos parsers existants
cp ../hyper_squirrel.js .
cp ../transpiller.js .
cp ../prism-parser.js .  # si disponible

# CrÃ©er les fichiers de test (voir artifacts ci-dessus)
# Ou tÃ©lÃ©charger depuis votre source
```

### 3. Permissions

```bash
chmod +x dsl-test-runner.sh
```

## ğŸ¯ Utilisation

### Tests basiques

```bash
# Tests standard avec tous les parsers
./dsl-test-runner.sh

# Tests avec parser spÃ©cifique
./dsl-test-runner.sh --parser transpiller

# Tests rapides seulement
./dsl-test-runner.sh --quick
```

### Tests avancÃ©s

```bash
# Tests dÃ©taillÃ©s avec rapport HTML
./dsl-test-runner.sh --verbose --html

# Tests de performance inclus
./dsl-test-runner.sh --performance

# Tests avec arrÃªt sur premiÃ¨re erreur
./dsl-test-runner.sh --stop-on-error
```

### Tests par catÃ©gorie

```bash
# Tests d'Ã©vÃ©nements seulement
./dsl-test-runner.sh --categories events

# Tests de base + syntaxe mixte
./dsl-test-runner.sh --categories basic,mixed_syntax

# Tests de non-rÃ©gression
./dsl-test-runner.sh --regression
```

## ğŸ“Š Types de tests

### 1. Tests de base (`basic`)
- CrÃ©ation d'objets A.new
- PropriÃ©tÃ©s et mÃ©thodes
- ChaÃ®nage de mÃ©thodes

```ruby
# Test automatique
container = A.new({
    id: 'test',
    width: 100,
    height: 100
})
```

### 2. Tests d'Ã©vÃ©nements (`events`)
- Gestionnaires onclick, onmouseover
- Ã‰vÃ©nements clavier avec paramÃ¨tres
- Blocs do...end

```ruby
# Test automatique
container.keyboard do |key|
    if key.ctrl && key.key == "s"
        puts "Ctrl+S dÃ©tectÃ©!"
        key.preventDefault
    end
end
```

### 3. Tests de temporisation (`timing`)
- Blocs wait...do
- setTimeout transpilÃ©

```ruby
# Test automatique
wait 3000 do
    puts "hello"
    grab('test').color("blue")
end
```

### 4. Tests d'interpolation (`string_interpolation`)
- Interpolation Ruby #{}
- Conversion vers template strings

```ruby
# Test automatique
puts "Valeur: #{variable}"
# Devient: puts(`Valeur: ${variable}`)
```

### 5. Tests de performance (`performance`)
- Vitesse de transpilation
- Utilisation mÃ©moire
- Gros fichiers DSL

### 6. Cas limites (`edge_cases`)
- Syntaxe incomplÃ¨te
- Blocs imbriquÃ©s profonds
- CaractÃ¨res spÃ©ciaux

## ğŸ“ˆ Rapports et analyse

### Format JSON (dÃ©faut)
```json
{
  "total": 45,
  "passed": 42,
  "failed": 3,
  "categories": {
    "basic_object_creation": { "passed": 8, "total": 8 },
    "event_handlers": { "passed": 12, "total": 14 }
  },
  "errors": [
    {
      "name": "keyboard avec paramÃ¨tre",
      "category": "event_handlers", 
      "dsl": "container.keyboard do |key|...",
      "transpiled": "container.addEventListener...",
      "executionError": "Syntax error...",
      "analysis": {
        "errorType": "Missing end keyword",
        "suggestions": ["Ajoutez le mot-clÃ© 'end'"]
      }
    }
  ]
}
```

### Rapport HTML interactif
- ğŸ“Š Graphiques de rÃ©ussite
- ğŸ” DÃ©tail des erreurs
- ğŸ’¡ Suggestions d'amÃ©lioration
- ğŸ“ Navigation par catÃ©gorie

## âš™ï¸ Configuration avancÃ©e

### Fichier de config personnalisÃ©

```javascript
// custom-config.js
module.exports = {
    general: {
        verbose: true,
        stopOnFirstError: false,
        timeout: 10000
    },
    parsers: {
        primary: 'hyper_squirrel',
        fallback: 'transpiller',
        loadFromFiles: true
    },
    testCategories: {
        basic_object_creation: true,
        event_handlers: true,
        performance: false,  // DÃ©sactiver tests lourds
        custom_api_tests: true
    },
    validation: {
        syntaxChecking: true,
        executionTesting: true,
        performanceChecking: false
    }
};
```

### Utilisation de la config

```bash
# Avec configuration personnalisÃ©e
./dsl-test-runner.sh --config custom-config.js
```

## ğŸ› Debugging et dÃ©pannage

### 1. Erreurs communes

#### Parser non trouvÃ©
```bash
âŒ Parser hyper_squirrel non trouvÃ©
```
**Solution :** VÃ©rifiez que le fichier existe et est accessible
```bash
ls -la *.js  # VÃ©rifier les parsers disponibles
./dsl-test-runner.sh --parser transpiller  # Utiliser un autre parser
```

#### Erreurs de transpilation
```bash
âŒ Pattern manquÃ©: /container\.onclick\(\(\) => \{/
```
**Solution :** Le parser ne gÃ©nÃ¨re pas le JS attendu
- VÃ©rifiez la syntaxe DSL
- Testez avec un parser diffÃ©rent
- Consultez le code transpilÃ© dans le rapport

#### Erreurs d'exÃ©cution
```bash
âŒ Erreur d'exÃ©cution: ReferenceError: A is not defined
```
**Solution :** Framework A non initialisÃ©
- VÃ©rifiez que le mock A est chargÃ©
- Mode verbose pour plus de dÃ©tails

### 2. Mode debug

```bash
# Debug complet
./dsl-test-runner.sh --verbose --stop-on-error

# Test unique catÃ©gorie
./dsl-test-runner.sh --categories basic --verbose

# Logs dÃ©taillÃ©s du parser
DEBUG=1 ./dsl-test-runner.sh
```

### 3. Validation manuelle

```bash
# Test rapide d'un parser
node -e "
const parser = require('./hyper_squirrel.js');
const result = parser.processHybridFile('container = A.new({id: \"test\"})');
console.log(result);
"
```

## ğŸ”§ Personnalisation

### Ajouter des tests personnalisÃ©s

```javascript
// Dans dsl-test-suite.js
const CUSTOM_TESTS = {
    my_api_tests: [
        {
            name: "API personnalisÃ©e",
            dsl: `container.myCustomMethod(params)`,
            expected_js_patterns: [
                /container\.myCustomMethod\(params\)/
            ]
        }
    ]
};

// Fusionner avec DSL_TEST_CASES
Object.assign(DSL_TEST_CASES, CUSTOM_TESTS);
```

### CrÃ©er un nouveau parser de test

```javascript
// custom-parser.js
class MyCustomParser {
    processHybridFile(code) {
        // Votre logique de transpilation
        return code.replace(/A\.new/g, 'new A');
    }
}

module.exports = MyCustomParser;
```

### MÃ©triques personnalisÃ©es

```javascript
// Dans dsl-test-config.js
class CustomMetrics {
    measureComplexity(code) {
        const lines = code.split('\n').length;
        const blocks = (code.match(/do\b/g) || []).length;
        return { lines, blocks, complexity: blocks / lines };
    }
}
```

## ğŸ“Š MÃ©triques et KPIs

### MÃ©triques automatiques

| MÃ©trique | Description | Seuil |
|----------|-------------|-------|
| Taux de rÃ©ussite | % tests passÃ©s | > 85% |
| Temps transpilation | ms par test | < 100ms |
| Couverture API | % APIs testÃ©es | > 90% |
| DÃ©tection erreurs | % erreurs trouvÃ©es | > 95% |

### Analyse de tendances

```bash
# Comparer les rapports dans le temps
ls test-reports/dsl-*.json | tail -5  # 5 derniers rapports

# Extraire mÃ©triques clÃ©s
jq '.passed, .total, (.passed/.total*100)' test-reports/dsl-*.json
```

## ğŸš€ IntÃ©gration CI/CD

### GitHub Actions

```yaml
# .github/workflows/dsl-tests.yml
name: Tests DSL
on: [push, pull_request]

jobs:
  test-dsl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: |
          sudo apt-get install -y jq bc
          
      - name: Run DSL tests
        run: |
          cd dsl-tests
          ./dsl-test-runner.sh --html --stop-on-error
          
      - name: Upload reports
        uses: actions/upload-artifact@v3
        with:
          name: dsl-test-reports
          path: dsl-tests/test-reports/
```

### Jenkins Pipeline

```groovy
pipeline {
    agent any
    stages {
        stage('DSL Tests') {
            steps {
                sh '''
                    cd dsl-tests
                    ./dsl-test-runner.sh --performance --html
                '''
            }
            post {
                always {
                    archiveArtifacts artifacts: 'dsl-tests/test-reports/*'
                    publishHTML([
                        allowMissing: false,
                        alwaysLinkToLastBuild: true,
                        keepAll: true,
                        reportDir: 'dsl-tests/test-reports',
                        reportFiles: '*.html',
                        reportName: 'DSL Test Report'
                    ])
                }
            }
        }
    }
}
```

## ğŸ“š RÃ©fÃ©rence API

### DSLTestEngine

```javascript
const engine = new DSLTestEngine({
    verbose: true,
    parser: 'hyper_squirrel'
});

await engine.init();
const results = await engine.runAllTests();
```

### AdvancedDSLTestEngine

```javascript
const engine = new AdvancedDSLTestEngine({
    general: { verbose: true },
    parsers: { primary: 'transpiller' },
    validation: { performanceChecking: true }
});

const results = await engine.runAdvancedTest(testCase, category);
```

### Configuration complÃ¨te

```javascript
{
    general: {
        verbose: boolean,
        stopOnFirstError: boolean,
        generateReport: boolean,
        timeout: number,
        outputDir: string
    },
    parsers: {
        primary: string,
        fallback: string,
        loadFromFiles: boolean,
        parserPaths: object
    },
    testCategories: {
        [category]: boolean
    },
    validation: {
        syntaxChecking: boolean,
        patternMatching: boolean,
        executionTesting: boolean,
        performanceChecking: boolean
    },
    reporting: {
        format: 'json' | 'html' | 'markdown',
        includeCode: boolean,
        includeSuggestions: boolean
    }
}
```

## ğŸ¯ Exemples d'utilisation

### Test d'un nouveau parser

```bash
# 1. Ajouter le parser
cp mon-nouveau-parser.js dsl-tests/

# 2. Tester rapidement
./dsl-test-runner.sh --parser mon-nouveau-parser --quick --verbose

# 3. Test complet si OK
./dsl-test-runner.sh --parser mon-nouveau-parser --html
```

### Debugging d'une feature

```bash
# 1. Test spÃ©cifique Ã  la feature
./dsl-test-runner.sh --categories events --verbose --stop-on-error

# 2. Analyser le rapport
jq '.errors[] | select(.category=="event_handlers")' test-reports/latest.json

# 3. Test unitaire
node -e "
const parser = require('./hyper_squirrel.js');
console.log(parser.processHybridFile('container.onclick do\nputs \"test\"\nend'));
"
```

### Benchmark de performance

```bash
# 1. Tests de performance complets
./dsl-test-runner.sh --performance --verbose

# 2. Comparer parsers
for parser in hyper_squirrel transpiller; do
    echo "=== $parser ==="
    ./dsl-test-runner.sh --parser $parser --performance --quick
done

# 3. Analyser mÃ©triques
jq '.performance' test-reports/dsl-*.json
```

## ğŸ›¡ï¸ SÃ©curitÃ© et bonnes pratiques

### Validation des entrÃ©es

```javascript
// Toujours valider le code DSL avant transpilation
function validateDSLCode(code) {
    if (!code || typeof code !== 'string') {
        throw new Error('Code DSL invalide');
    }
    
    // VÃ©rifier les patterns dangereux
    const dangerousPatterns = [
        /eval\(/,
        /Function\(/,
        /require\(['"]\./  // Require relatif
    ];
    
    for (const pattern of dangerousPatterns) {
        if (pattern.test(code)) {
            throw new Error('Code DSL potentiellement dangereux');
        }
    }
}
```

### Sandbox d'exÃ©cution

```javascript
// ExÃ©cuter en mode sandbox
function executeInSandbox(jsCode) {
    const vm = require('vm');
    const sandbox = {
        A: MockFrameworkA,
        puts: console.log,
        grab: mockGrab,
        setTimeout: setTimeout
    };
    
    try {
        vm.runInNewContext(jsCode, sandbox, { timeout: 1000 });
    } catch (error) {
        console.error('Erreur sandbox:', error.message);
    }
}
```

## ğŸ”„ Maintenance et mises Ã  jour

### Tests de rÃ©gression

```bash
# Avant une mise Ã  jour majeure
./dsl-test-runner.sh --regression > regression-baseline.txt

# AprÃ¨s la mise Ã  jour
./dsl-test-runner.sh --regression > regression-current.txt

# Comparer
diff regression-baseline.txt regression-current.txt
```

### Ajout de nouveaux tests

```javascript
// 1. Identifier le pattern problÃ©matique
const newTest = {
    name: "Nouveau pattern problÃ©matique",
    dsl: `nouveau_code_dsl_qui_plante`,
    expected_js_patterns: [/pattern_attendu/],
    bug_id: "BUG-XXX"
};

// 2. L'ajouter aux tests de rÃ©gression
REGRESSION_TESTS.known_fixes.push(newTest);

// 3. VÃ©rifier qu'il Ã©choue avant le fix
// 4. Fixer le parser
// 5. VÃ©rifier qu'il passe aprÃ¨s le fix
```

### Nettoyage des rapports

```bash
# Script de nettoyage automatique
#!/bin/bash
# clean-old-reports.sh

REPORTS_DIR="./test-reports"
DAYS_TO_KEEP=30

find "$REPORTS_DIR" -type f -name "*.json" -mtime +$DAYS_TO_KEEP -delete
find "$REPORTS_DIR" -type f -name "*.html" -mtime +$DAYS_TO_KEEP -delete

echo "Rapports de plus de $DAYS_TO_KEEP jours supprimÃ©s"
```

## ğŸ“ Support et contribution

### Signaler un bug

1. ExÃ©cuter avec `--verbose --stop-on-error`
2. Inclure le code DSL problÃ©matique
3. Joindre le rapport JSON
4. SpÃ©cifier le parser utilisÃ©

### Contribuer

1. Fork du projet
2. Ajouter des tests pour votre feature
3. S'assurer que tous les tests passent
4. Proposer une PR avec description dÃ©taillÃ©e

### Ressources

- ğŸ“– [Documentation du Framework A](lien-vers-doc)
- ğŸ› [Issues GitHub](lien-vers-issues)  
- ğŸ’¬ [Discussions](lien-vers-discussions)
- ğŸ“Š [MÃ©triques live](lien-vers-dashboard)

---

## ğŸ‰ Conclusion

Ce systÃ¨me de tests vous permet de :

âœ… **DÃ©tecter automatiquement** les problÃ¨mes de transpilation  
âœ… **Valider toutes les APIs** de votre framework  
âœ… **Analyser les performances** et optimiser  
âœ… **GÃ©nÃ©rer des rapports** pour le suivi  
âœ… **IntÃ©grer en CI/CD** pour la qualitÃ© continue  

**Commencez maintenant :**

```bash
chmod +x dsl-test-runner.sh
./dsl-test-runner.sh --quick --html
```

Votre DSL Ruby/JS sera plus robuste et fiable ! ğŸš€